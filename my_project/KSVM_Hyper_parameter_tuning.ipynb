{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Twitter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.learning_curve import validation_curve\n",
    "from sklearn.grid_search import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_input(frozen_dir='./private/files/seodam_together_notags0326.csv', unfrozen_dir='./private/files/unfrozen_mixed0402.csv', row_limit=3211):\n",
    "    df_frozen = pd.read_csv(frozen_dir).drop(['Unnamed: 0'], axis=1)\n",
    "    df_unfrozen = pd.read_csv(unfrozen_dir).drop(['Unnamed: 0'], axis=1)[:row_limit]\n",
    "\n",
    "    unfrozen = np.array(df_unfrozen['text2'])\n",
    "    frozen = np.array(df_frozen['text'])\n",
    "\n",
    "    weight0 = np.append(np.array(np.ones(row_limit, dtype=int)), np.array(df_frozen['freeze']))\n",
    "    seodam_x = np.append(unfrozen, frozen)\n",
    "    seodam_y = np.append(np.zeros(row_limit, dtype=int), np.ones(row_limit, dtype=int))\n",
    "    return (seodam_x, seodam_y, weight0)\n",
    "\n",
    "def tokenize_basic(doc):\n",
    "    pos_tagger = Twitter()\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]\n",
    "\n",
    "def tokenize_noun(doc):\n",
    "    pos_tagger = Twitter()\n",
    "    return pos_tagger.nouns(doc)\n",
    "\n",
    "def tokenize_filtered(doc):\n",
    "    tagger = Twitter()\n",
    "    token_list = []\n",
    "    for t in tagger.pos(doc, norm=True, stem=True):\n",
    "        if t[1] != 'Josa' and t[1] != 'Punctuation' and t[1] != 'Determiner' and t[1] != 'URL' :\n",
    "            token_list.append('/'.join(t))\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X0, y, weight = cv_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_range=np.linspace(1,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(tokenizer=tokenize_filtered)\n",
    "X = vect.fit_transform(X0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_score2, test_score2 = validation_curve(SVC(kernel='linear'), X, y, param_name=\"C\", param_range=param_range, cv=5, scoring='recall', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63608087,  0.59968847,  0.56697819,  0.61370717,  0.57788162],\n",
       "       [ 0.62986003,  0.59501558,  0.57009346,  0.61838006,  0.59190031],\n",
       "       [ 0.63297045,  0.59657321,  0.5623053 ,  0.60903427,  0.59034268],\n",
       "       [ 0.63763608,  0.59968847,  0.5529595 ,  0.61370717,  0.58878505],\n",
       "       [ 0.63452566,  0.60903427,  0.55140187,  0.59968847,  0.58566978]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12597201,  0.00623053,  0.        ,  0.00623053,  0.        ],\n",
       "       [ 0.01710731,  0.00623053,  0.        ,  0.00311526,  0.        ],\n",
       "       [ 0.01399689,  0.01557632,  0.        ,  0.00311526,  0.        ],\n",
       "       [ 0.06531882,  0.06697819,  0.        ,  0.00311526,  0.00155763],\n",
       "       [ 0.18195956,  0.17757009,  0.02492212,  0.03115265,  0.03582555],\n",
       "       [ 0.36702955,  0.33489097,  0.13395639,  0.1588785 ,  0.15109034],\n",
       "       [ 0.50388802,  0.47040498,  0.28193146,  0.35981308,  0.27725857],\n",
       "       [ 0.58631415,  0.5482866 ,  0.42523364,  0.51090343,  0.3894081 ],\n",
       "       [ 0.6407465 ,  0.605919  ,  0.54049844,  0.57009346,  0.53115265],\n",
       "       [ 0.63608087,  0.59968847,  0.56697819,  0.61370717,  0.57788162]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize_filtered)),\n",
    "        ('clf', SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_range = np.logspace(-4,3,8)\n",
    "param_grid = [{'clf__C': param_range, 'clf__gamma':param_range, 'clf__kernel':['rbf']}]\n",
    "\n",
    "cv = ShuffleSplit(6422)\n",
    "gs = GridSearchCV(estimator=model, param_grid=param_grid, fit_params={'clf__sample_weigth':weight}, cv=cv, scoring='recall', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs.fit(X,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
