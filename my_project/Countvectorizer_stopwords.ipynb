{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from konlpy.tag import Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>freeze</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>3206</td>\n",
       "      <td>5</td>\n",
       "      <td>그냥 바람피면 되지 뭘 그렇게 정리를 하고 그러냐. 다른 여자도 좀 만나고 하면 다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3207</th>\n",
       "      <td>3207</td>\n",
       "      <td>1</td>\n",
       "      <td>실제로 예수회조져야한다고 공감하는 사람 많은지도 모르겠음 이젠 물도끝났고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208</th>\n",
       "      <td>3208</td>\n",
       "      <td>5</td>\n",
       "      <td>걍 쇠가 다 식은게 느껴짐 이학교는 끝났지뭐 ㅋㅋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>3209</td>\n",
       "      <td>6</td>\n",
       "      <td>내려갈 일만 남았다 ^오^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>3210</td>\n",
       "      <td>1</td>\n",
       "      <td>그런사람없다 ㅇㅇ 있어도 극소수일테니 걱정마라</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  freeze                                               text\n",
       "3206        3206       5  그냥 바람피면 되지 뭘 그렇게 정리를 하고 그러냐. 다른 여자도 좀 만나고 하면 다...\n",
       "3207        3207       1           실제로 예수회조져야한다고 공감하는 사람 많은지도 모르겠음 이젠 물도끝났고\n",
       "3208        3208       5                        걍 쇠가 다 식은게 느껴짐 이학교는 끝났지뭐 ㅋㅋ\n",
       "3209        3209       6                                    내려갈 일만 남았다 ^오^ \n",
       "3210        3210       1                         그런사람없다 ㅇㅇ 있어도 극소수일테니 걱정마라 "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./private/files/seodam_together_notags0326.csv')\n",
    "df2 = pd.read_csv('./private/files/unfrozen2_3500.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>3495</td>\n",
       "      <td>2016/10/30 13:35</td>\n",
       "      <td>(재업) 서강대 점공카페 운위모집 선발인원 : 7명 (작성자 본인을 제외한 6명) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>3496</td>\n",
       "      <td>2016/10/30 13:35</td>\n",
       "      <td>상하이 vs 베이징 군복무중인 다미인데        전역후 중국여행 계획중인데   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>3497</td>\n",
       "      <td>2016/10/30 13:39</td>\n",
       "      <td>예수회 외에는 우리학교 운영할 사람이 없어.       예수회는 아버지 아닙니까? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>3498</td>\n",
       "      <td>2016/10/30 13:45</td>\n",
       "      <td>교수의 우선순위가 뭔지 아는가? 1위는 대학원생 갈구기 2위는 실적 올리기, 채점 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>3499</td>\n",
       "      <td>2016/10/30 13:48</td>\n",
       "      <td>노무현 발언들 찬찬히 살펴봤는데 진짜 이 사람은 국회의원 한 7선 시켰어야 했다. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0              date  \\\n",
       "3385        3495  2016/10/30 13:35   \n",
       "3386        3496  2016/10/30 13:35   \n",
       "3387        3497  2016/10/30 13:39   \n",
       "3388        3498  2016/10/30 13:45   \n",
       "3389        3499  2016/10/30 13:48   \n",
       "\n",
       "                                                  text2  \n",
       "3385  (재업) 서강대 점공카페 운위모집 선발인원 : 7명 (작성자 본인을 제외한 6명) ...  \n",
       "3386  상하이 vs 베이징 군복무중인 다미인데        전역후 중국여행 계획중인데   ...  \n",
       "3387  예수회 외에는 우리학교 운영할 사람이 없어.       예수회는 아버지 아닙니까? ...  \n",
       "3388  교수의 우선순위가 뭔지 아는가? 1위는 대학원생 갈구기 2위는 실적 올리기, 채점 ...  \n",
       "3389  노무현 발언들 찬찬히 살펴봤는데 진짜 이 사람은 국회의원 한 7선 시켰어야 했다. ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_input(frozen_dir='./private/files/seodam_together_notags0326.csv', unfrozen_dir='./private/files/unfrozen2_3500.csv', row_limit=3211):\n",
    "    df_frozen = pd.read_csv(frozen_dir).drop(['Unnamed: 0'], axis=1)\n",
    "    df_unfrozen = pd.read_csv(unfrozen_dir).drop(['Unnamed: 0'], axis=1)[:row_limit]\n",
    "    \n",
    "    unfrozen = np.array(df_unfrozen['text2'])\n",
    "    frozen = np.array(df_frozen['text'])\n",
    "    weight0 = np.append(np.array(np.ones(row_limit, dtype=int)), np.array(df_frozen['freeze']))\n",
    "    seodam_x = np.append(unfrozen, frozen)\n",
    "    seodam_y = np.append(np.zeros(row_limit, dtype=int), np.ones(row_limit, dtype=int))\n",
    "    \n",
    "    return (seodam_x, seodam_y, weight0)\n",
    "\n",
    "def make_stopwords(stwd_dir='stopwords.txt'):\n",
    "    stop_words = []\n",
    "    with open(stwd_dir, 'r') as reader :\n",
    "        stop_words0 = reader.readlines()\n",
    "        stop_words1 = stop_words0[0].split(',')\n",
    "    for words in stop_words1:\n",
    "        stop_words.append(words.decode('utf-8'))\n",
    "    \n",
    "    return stop_words\n",
    "\n",
    "def tokenize(doc):\n",
    "    tagger = Twitter()\n",
    "    token_list = []\n",
    "    for t in tagger.pos(doc, norm=True, stem=True):\n",
    "        if t[1] != 'Josa' and t[1] != 'Punctuation' and t[1] != 'Determiner' and t[1] != 'URL' :\n",
    "            token_list.append('/'.join(t))\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample_weight 없이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(6422, random_state=0)\n",
    "recall_rate = cross_val_score(model, seodam_x, seodam_y, scoring='recall', cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80120482  0.7987013   0.83024691  0.79635258  0.8496732   0.81213873\n",
      "  0.81168831  0.81927711  0.8044164   0.81987578]\n",
      "0.814357514639\n"
     ]
    }
   ],
   "source": [
    "print recall_rate\n",
    "print recall_rate.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample_weight 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(6422, random_state=0)\n",
    "recall_rate = cross_val_score(model, seodam_x, seodam_y, scoring='recall', cv=cv, fit_params={'clf__sample_weight' : weight0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.81626506  0.81168831  0.84567901  0.80547112  0.84313725  0.82080925\n",
      "  0.8474026   0.84638554  0.84542587  0.85093168]\n",
      "0.833319569645\n"
     ]
    }
   ],
   "source": [
    "print recall_rate\n",
    "print recall_rate.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.78      0.79       311\n",
      "          1       0.80      0.82      0.81       332\n",
      "\n",
      "avg / total       0.80      0.80      0.80       643\n",
      "\n",
      "**************************************************\n",
      "1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.71      0.76       335\n",
      "          1       0.72      0.81      0.76       308\n",
      "\n",
      "avg / total       0.77      0.76      0.76       643\n",
      "\n",
      "**************************************************\n",
      "2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.78      0.81       319\n",
      "          1       0.80      0.85      0.82       324\n",
      "\n",
      "avg / total       0.81      0.81      0.81       643\n",
      "\n",
      "**************************************************\n",
      "3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.78      0.79       314\n",
      "          1       0.80      0.81      0.80       329\n",
      "\n",
      "avg / total       0.79      0.79      0.79       643\n",
      "\n",
      "**************************************************\n",
      "4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.75      0.79       337\n",
      "          1       0.75      0.84      0.80       306\n",
      "\n",
      "avg / total       0.80      0.79      0.79       643\n",
      "\n",
      "**************************************************\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.74      0.76       297\n",
      "          1       0.79      0.82      0.80       346\n",
      "\n",
      "avg / total       0.78      0.78      0.78       643\n",
      "\n",
      "**************************************************\n",
      "6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.72      0.78       335\n",
      "          1       0.74      0.85      0.79       308\n",
      "\n",
      "avg / total       0.79      0.78      0.78       643\n",
      "\n",
      "**************************************************\n",
      "7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.74      0.78       311\n",
      "          1       0.78      0.85      0.81       332\n",
      "\n",
      "avg / total       0.80      0.80      0.80       643\n",
      "\n",
      "**************************************************\n",
      "8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.81      0.83       326\n",
      "          1       0.81      0.85      0.83       317\n",
      "\n",
      "avg / total       0.83      0.83      0.83       643\n",
      "\n",
      "**************************************************\n",
      "9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.73      0.78       321\n",
      "          1       0.76      0.85      0.80       322\n",
      "\n",
      "avg / total       0.80      0.79      0.79       643\n",
      "\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "cv = ShuffleSplit(6422, random_state=0)\n",
    "for k, (train_index, test_index) in enumerate(cv):\n",
    "    X_train0 = seodam_x[train_index]\n",
    "    y_train = seodam_y[train_index]\n",
    "    X_test0 = seodam_x[test_index]\n",
    "    \n",
    "    model.fit(X_train0, y_train, **{\"clf__sample_weight\" : weight0[train_index]})\n",
    "    result = model.predict(X_test0)\n",
    "    print k\n",
    "    print classification_report(seodam_y[test_index], result)\n",
    "    print \"*\" * 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger = Twitter()\n",
    "def tokenize(doc):\n",
    "    token_list = []\n",
    "    for t in tagger.pos(doc, norm=True, stem=True):\n",
    "        if t[1] != 'Josa' and t[1] != 'Punctuation' and t[1] != 'Determiner' and t[1] != 'URL' :\n",
    "            token_list.append('/'.join(t))\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(tokenizer=tokenize, stop_words=stop_words2[:15])\n",
    "vect.fit(X_train)\n",
    "X_train = vect.transform(X_train)\n",
    "X_test = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.79      0.80       316\n",
      "          1       0.80      0.82      0.81       327\n",
      "\n",
      "avg / total       0.80      0.80      0.80       643\n",
      "\n",
      "\n",
      "[[250  66]\n",
      " [ 60 267]]\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, result)\n",
    "print \n",
    "print confusion_matrix(y_test, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidv = TfidfVectorizer(tokenizer=tokenize, stop_words=stop_words2[:15])\n",
    "X_train = tfidv.fit_transform(X_train)\n",
    "X_test = tfidv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.86      0.82       316\n",
      "          1       0.85      0.76      0.81       327\n",
      "\n",
      "avg / total       0.82      0.81      0.81       643\n",
      "\n",
      "\n",
      "[[273  43]\n",
      " [ 77 250]]\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, result)\n",
    "print\n",
    "print confusion_matrix(y_test, result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
