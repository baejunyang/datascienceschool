{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False negative, False positive 샘플 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_input(frozen_dir='./private/files/seodam_together_notags0326.csv', unfrozen_dir='./private/files/unfrozen_mixed0402.csv', row_limit=3211):\n",
    "    df_frozen = pd.read_csv(frozen_dir).drop(['Unnamed: 0'], axis=1)\n",
    "    df_unfrozen = pd.read_csv(unfrozen_dir).drop(['Unnamed: 0'], axis=1)[:row_limit]\n",
    "\n",
    "    unfrozen = np.array(df_unfrozen['text2'])\n",
    "    frozen = np.array(df_frozen['text'])\n",
    "\n",
    "    weight0 = np.append(np.array(np.ones(row_limit, dtype=int)), np.array(df_frozen['freeze']))\n",
    "    seodam_x = np.append(unfrozen, frozen)\n",
    "    seodam_y = np.append(np.zeros(row_limit, dtype=int), np.ones(row_limit, dtype=int))\n",
    "    return (seodam_x, seodam_y, weight0)\n",
    "\n",
    "def tokenize_filtered(doc):\n",
    "    tagger = Twitter()\n",
    "    token_list = []\n",
    "    for t in tagger.pos(doc, norm=True, stem=True):\n",
    "        if t[1] != 'Josa' and t[1] != 'Punctuation' and t[1] != 'Determiner' and t[1] != 'URL' :\n",
    "            token_list.append('/'.join(t))\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FalseSamples(object):\n",
    "    def __init__(self, X, y, w, tokenize=tokenize_filtered, weight=False, stop_words=None, random_state=0):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.tokenize = tokenize\n",
    "        self.weight = weight\n",
    "        self.stop_words = stop_words\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def simple_split(self):\n",
    "        X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(self.X, self.y, self.w, test_size=0.1, random_state=self.random_state)\n",
    "        return X_train, X_test, y_train, y_test, w_train        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y, weight = cv_input()\n",
    "X_train0, X_test0, y_train, y_test, w_train, w_test = train_test_split(X, y, weight, test_size=0.1)\n",
    "\n",
    "vect = CountVectorizer(tokenizer=tokenize_filtered)\n",
    "X_train = vect.fit_transform(X_train0)\n",
    "X_test = vect.transform(X_test0)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train, sample_weight=w_train)\n",
    "result = clf.predict(X_test)\n",
    "\n",
    "mask_fn = np.logical_and(y_test==0, result==1)\n",
    "mask_fp = np.logical_and(y_test==1, result==0)\n",
    "\n",
    "#false_negative = [text.decode('utf-8') for text in X_test[mask_fn]]\n",
    "#false_positive = [text.decode('utf-8') for text in X_test[mask_fp]]\n",
    "\n",
    "report = confusion_matrix(y_test, result)\n",
    "recall_rate = float(report[1,1]) / (report[1,0] + report[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_X = pd.DataFrame(X_test0, columns=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 1(냉동)인데 0(정상)으로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>결혼을 누구랑 하느냐는 팔자인듯 내가 사주랑 손금 관심이 있는데..(전에여기서 손금...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>내가 결혼하기전에 꼬옥! 달성할 목표 세다리 !?양다리는 두 번정도 해봤음 삼다리만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>너희들의 인생치킨집(신촌) 알려줘 여친님께서 치킨이 고프다고하셔데이트때 맛난데로 가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>경제로볼걸ㅅㅂ 경영문제낸ㅅㄲ죽이고싶다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[대외교류처] 업무보조 근로장학생 모집  대외교류처(발전홍보팀)에서 업무보조학생 O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>경상도는 나라를 팔아도 새누리전라도는 같이 팔아도 국민의당</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>이거 비대위장 맞냐? *많이 먹어 비대해진 위장이다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>근데 자연대 학점 2점 초반대 맞은 사람이 기술고시 변리사 한다고 해서 잘될거라고는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>일본의 13살 vs 20살 오른쪽이 20살 ㄷㄷ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>동성애 다괜찬은데 모텔에서 샤워기뚜껑빼고 그걸로 관장안햇으면 좋겟다 다음으로 들어간...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>여자친구랑 방금 싸웠다.... 침대에서 주도권을 잡기 위해알몸으로 싸웠다....주도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>회장은 누군지도 모르는데 부회장 혼자 설치지않음?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>너한테 그렇게 엄격해져보거라</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>학교에서 공학가면 12시반쯔음 되겠다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>전 붙엇는데염</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>★다가오는 겨울을 위한 남다미들 코트 구매 팁(스압)★ 농구코트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>태명은 다미 어때</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>새해 덕담 ㅋㅋㅋㅋㅋㅋㅋㅋ 캡쳐 개절묘하네 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>산업은행이 사기업으로 치면 어느정도 급인가요?? 저학번이라서 잘 모르니 너무 뭐라하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>그나저나 감사함 우리학교 브랜드 이미지 안좋아지게 오르비등에 내부적 문제 올려주신 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>중앙일보 대학평가도 못믿어,QS 대학평가도 못믿어,서울시 입결도 못믿어,뭔 자료만 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>19..질문하나만 노콘노섹하는 커플인데ㄷ옆으로 누워서 백허그하고 할때 유독 콘돔이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>게이의 헤어짐... 작년 1월 말에 처음 만났어얘기는 잘 통했지만 날 친구이상으로 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>지원자가 적은지 딱히 인물들은 없던데 한두 명 제외 ㅋㅋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>동물 보호법 주장하는사람 특징 개 고양이 같은 귀여운 동물만 보호하자고함못생기고 냄...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>멘탈 정말 강한듯 걱정했는데 괜찮아보이네대단</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>약혐) 밤꽃냄새 너무 좋다 남잔데팬티 가끔씩 껴서 다듬으면 밤꽃냄새 올라오는데 너무...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>LINC교수 SIAT교수전직차관 정년보장정교수 임용이런 것부터 토론합시다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>공학관AS관은 박홍신부가 기부받아 왔음그밖에 다산관 등 박홍신부의 fund  rai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>action changes sogang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>[설문] SHQ(서강인재지수) 설문조사 참여자 모집 (마감) 안녕하세요. 창의인재개...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>?? 걍 리트 ㅍㅌㅊ나올거 가정해서 성로되는지 물은건데. 그럼 내가 내인생인데 리트...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>예비 변시 낭인아 여기서 시간 낭비 잘하소~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>기업 - 이익추구의 사집단대학 - 그래도 국가에서 돈 많이 받는 재단기업 - 지원의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>엄마 삐침 ㅠㅠㅠㅠ 곧 부모님 결혼기념일이라 아빠가 나보고 엄마한테 선물할 핸드폰 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>그랬다간 새누리당에서 친박이 갈라져 나온 뒤에 친박연대2를 세울 수도 있음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>내가 예언 하나 해봄 최 장 정 김승마?한화삼성내가 따로 커뮤니티 하는것도 없고 해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>빨강 프리퀀시 하나만 기부해주세요 부탁드려요 ㅠㅠㅠ딱 한개만 있으면 되는데 (내일밖...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "21   결혼을 누구랑 하느냐는 팔자인듯 내가 사주랑 손금 관심이 있는데..(전에여기서 손금...\n",
       "34   내가 결혼하기전에 꼬옥! 달성할 목표 세다리 !?양다리는 두 번정도 해봤음 삼다리만...\n",
       "50   너희들의 인생치킨집(신촌) 알려줘 여친님께서 치킨이 고프다고하셔데이트때 맛난데로 가...\n",
       "57                                경제로볼걸ㅅㅂ 경영문제낸ㅅㄲ죽이고싶다\n",
       "60   [대외교류처] 업무보조 근로장학생 모집  대외교류처(발전홍보팀)에서 업무보조학생 O...\n",
       "87                    경상도는 나라를 팔아도 새누리전라도는 같이 팔아도 국민의당\n",
       "103                       이거 비대위장 맞냐? *많이 먹어 비대해진 위장이다\n",
       "107  근데 자연대 학점 2점 초반대 맞은 사람이 기술고시 변리사 한다고 해서 잘될거라고는...\n",
       "110                         일본의 13살 vs 20살 오른쪽이 20살 ㄷㄷ\n",
       "112  동성애 다괜찬은데 모텔에서 샤워기뚜껑빼고 그걸로 관장안햇으면 좋겟다 다음으로 들어간...\n",
       "115  여자친구랑 방금 싸웠다.... 침대에서 주도권을 잡기 위해알몸으로 싸웠다....주도...\n",
       "120                        회장은 누군지도 모르는데 부회장 혼자 설치지않음?\n",
       "137                                    너한테 그렇게 엄격해져보거라\n",
       "189                               학교에서 공학가면 12시반쯔음 되겠다\n",
       "239                                            전 붙엇는데염\n",
       "262                ★다가오는 겨울을 위한 남다미들 코트 구매 팁(스압)★ 농구코트\n",
       "266                                          태명은 다미 어때\n",
       "267                 새해 덕담 ㅋㅋㅋㅋㅋㅋㅋㅋ 캡쳐 개절묘하네 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ\n",
       "269  산업은행이 사기업으로 치면 어느정도 급인가요?? 저학번이라서 잘 모르니 너무 뭐라하...\n",
       "279  그나저나 감사함 우리학교 브랜드 이미지 안좋아지게 오르비등에 내부적 문제 올려주신 ...\n",
       "287  중앙일보 대학평가도 못믿어,QS 대학평가도 못믿어,서울시 입결도 못믿어,뭔 자료만 ...\n",
       "335  19..질문하나만 노콘노섹하는 커플인데ㄷ옆으로 누워서 백허그하고 할때 유독 콘돔이 ...\n",
       "369  게이의 헤어짐... 작년 1월 말에 처음 만났어얘기는 잘 통했지만 날 친구이상으로 ...\n",
       "373                    지원자가 적은지 딱히 인물들은 없던데 한두 명 제외 ㅋㅋ\n",
       "380  동물 보호법 주장하는사람 특징 개 고양이 같은 귀여운 동물만 보호하자고함못생기고 냄...\n",
       "383                           멘탈 정말 강한듯 걱정했는데 괜찮아보이네대단\n",
       "426  약혐) 밤꽃냄새 너무 좋다 남잔데팬티 가끔씩 껴서 다듬으면 밤꽃냄새 올라오는데 너무...\n",
       "454           LINC교수 SIAT교수전직차관 정년보장정교수 임용이런 것부터 토론합시다\n",
       "470  공학관AS관은 박홍신부가 기부받아 왔음그밖에 다산관 등 박홍신부의 fund  rai...\n",
       "509                              action changes sogang\n",
       "518  [설문] SHQ(서강인재지수) 설문조사 참여자 모집 (마감) 안녕하세요. 창의인재개...\n",
       "536  ?? 걍 리트 ㅍㅌㅊ나올거 가정해서 성로되는지 물은건데. 그럼 내가 내인생인데 리트...\n",
       "572                           예비 변시 낭인아 여기서 시간 낭비 잘하소~\n",
       "574  기업 - 이익추구의 사집단대학 - 그래도 국가에서 돈 많이 받는 재단기업 - 지원의...\n",
       "604  엄마 삐침 ㅠㅠㅠㅠ 곧 부모님 결혼기념일이라 아빠가 나보고 엄마한테 선물할 핸드폰 ...\n",
       "616          그랬다간 새누리당에서 친박이 갈라져 나온 뒤에 친박연대2를 세울 수도 있음\n",
       "622  내가 예언 하나 해봄 최 장 정 김승마?한화삼성내가 따로 커뮤니티 하는것도 없고 해...\n",
       "639  빨강 프리퀀시 하나만 기부해주세요 부탁드려요 ㅠㅠㅠ딱 한개만 있으면 되는데 (내일밖..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.ix[mask_fp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 0(정상)인데 1(냉동)으로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_X.ix[mask_fn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클래스별 중요한 단어 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "important_0 = []\n",
    "for i, prob in enumerate(clf.feature_log_prob_[0]):\n",
    "    if prob > -7:\n",
    "        important_0.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "important_1 = []\n",
    "for i, prob in enumerate(clf.feature_log_prob_[1]):\n",
    "    if prob > -7:\n",
    "        important_1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voca = sorted(vect.vocabulary_.items(), key=lambda x : x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0(정상)인 글에 등장할 확률이 높은 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4/Number, 226),\n",
      " (5/Number, 255),\n",
      " (a/Alpha, 369),\n",
      " (and/Alpha, 439),\n",
      " (of/Alpha, 1520),\n",
      " (our/Alpha, 1557),\n",
      " (that/Alpha, 2062),\n",
      " (the/Alpha, 2063),\n",
      " (to/Alpha, 2096),\n",
      " (we/Alpha, 2220),\n",
      " (’/Foreign, 2324),\n",
      " (ㅎㅎ/KoreanParticle, 2517),\n",
      " (ㅠㅠ/KoreanParticle, 2547),\n",
      " (공부/Noun, 3636),\n",
      " (교수/Noun, 3831),\n",
      " (면접/Noun, 7136),\n",
      " (시간/Noun, 10375),\n",
      " (제/Noun, 14194),\n",
      " (준비/Noun, 14591),\n",
      " (지원/Noun, 14839),\n",
      " (친구/Noun, 15734),\n",
      " (학기/Noun, 17026)]\n"
     ]
    }
   ],
   "source": [
    "xx = []\n",
    "for i in important_0:\n",
    "    if i not in important_1:\n",
    "        xx.append(voca[i])\n",
    "pprint(xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(냉동)인 글에 등장할 확률이 높은 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(가지/Noun, 2708),\n",
      " (게/Noun, 3238),\n",
      " (경우/Noun, 3348),\n",
      " (그리고/Conjunction, 4195),\n",
      " (나가다/Verb, 4762),\n",
      " (남양주/Noun, 4932),\n",
      " (남자/Noun, 4936),\n",
      " (내다/Verb, 4994),\n",
      " (니/Noun, 5377),\n",
      " (대통령/Noun, 5763),\n",
      " (대한/Noun, 5787),\n",
      " (댓글/Noun, 5806),\n",
      " (돈/Noun, 5979),\n",
      " (돼다/Verb, 6098),\n",
      " (되어다/Verb, 6108),\n",
      " (따다/Verb, 6305),\n",
      " (또/Noun, 6383),\n",
      " (못/Noun, 7317),\n",
      " (박근혜/Noun, 7762),\n",
      " (병신/Noun, 8277),\n",
      " (보이다/Verb, 8337),\n",
      " (분들/Suffix, 8600),\n",
      " (뽑다/Verb, 9016),\n",
      " (사실/Noun, 9129),\n",
      " (사회/Noun, 9206),\n",
      " (새끼/Noun, 9369),\n",
      " (소리/Noun, 9871),\n",
      " (수준/Noun, 10120),\n",
      " (시키다/Verb, 10464),\n",
      " (쓸다/Verb, 10785),\n",
      " (애/Noun, 11152),\n",
      " (얘기/Noun, 11313),\n",
      " (여기/Noun, 11634),\n",
      " (여성/Noun, 11667),\n",
      " (여자/Noun, 11686),\n",
      " (올리다/Verb, 12118),\n",
      " (와/Noun, 12136),\n",
      " (외교관/Noun, 12210),\n",
      " (위/Noun, 12526),\n",
      " (이사회/Noun, 12980),\n",
      " (이유/Noun, 13035),\n",
      " (자기/Noun, 13460),\n",
      " (잘못/Noun, 13624),\n",
      " (존나/Noun, 14371),\n",
      " (주다/Verb, 14498),\n",
      " (지다/Verb, 14775),\n",
      " (직원/Noun, 14900),\n",
      " (취업/Noun, 15662),\n",
      " (학생/Noun, 17044),\n",
      " (한국/Noun, 17081),\n",
      " (함/Noun, 17172)]\n"
     ]
    }
   ],
   "source": [
    "yy = []\n",
    "for i in important_1:\n",
    "    if i not in important_0:\n",
    "        yy.append(voca[i])\n",
    "pprint(yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 냉동 단어들 vs 비 냉동 단어들 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_filtered(doc):\n",
    "    tagger = Twitter()\n",
    "    token_list = []\n",
    "    for t in tagger.pos(doc, norm=True, stem=True):\n",
    "        if t[1] != 'Josa' and t[1] != 'Punctuation' and t[1] != 'Determiner' and t[1] != 'URL' and t[1] != 'Alpha' :\n",
    "            token_list.append('/'.join(t))\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_frozen = pd.read_csv('./private/files/seodam_together_notags0322.csv').drop(['Unnamed: 0'], axis=1)\n",
    "df_unfrozen = pd.read_csv('./private/files/unfrozen_mixed0402.csv').drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frozen_str = ' '.join(df_frozen.text.values).decode('utf-8')\n",
    "unfrozen_str = ' '.join(df_unfrozen.text2.values).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frozen_words = tokenize_filtered(frozen_str)\n",
    "unfrozen_words = tokenize_filtered(unfrozen_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frozen_count = Counter(frozen_words)\n",
    "unfrozen_count = Counter(unfrozen_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff_frozen = {}\n",
    "for k, v in frozen_count.items():\n",
    "    if k in unfrozen_words:\n",
    "        diff_frozen[k] = v - unfrozen_count[k]\n",
    "    else :\n",
    "        diff_frozen[k] = v\n",
    "\n",
    "diff_unfrozen = {}\n",
    "for k, v in unfrozen_count.items():\n",
    "    if k in frozen_words:\n",
    "        diff_unfrozen[k] = v - frozen_count[k]\n",
    "    else:\n",
    "        diff_unfrozen[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frozen_sort = sorted(diff_frozen.items(), key=lambda x: x[1], reverse=True)\n",
    "unfrozen_sort = sorted(diff_unfrozen.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "워드클라우드 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frozen_lst = []\n",
    "for pos in frozen_sort[:30]:\n",
    "    removed = re.sub(r'/\\w+', '', pos[0])\n",
    "    tup = (removed, pos[1])\n",
    "    frozen_lst.append(tup)\n",
    "\n",
    "unfrozen_lst = []\n",
    "for pos in unfrozen_sort[:30]:\n",
    "    removed = re.sub(r'/\\w+', '', pos[0])\n",
    "    tup = (removed, pos[1])\n",
    "    unfrozen_lst.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pytagcloud\n",
    "\n",
    "tag_frozen = frozen_lst\n",
    "tag_unfrozen = unfrozen_lst\n",
    "\n",
    "taglist = pytagcloud.make_tags(tag_frozen, maxsize=150)\n",
    "taglist2 = pytagcloud.make_tags(tag_unfrozen, maxsize=100)\n",
    "\n",
    "pytagcloud.create_tag_image(taglist, 'wordcloud_f.jpg', fontname='Korean', size=(500, 320), layout=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pytagcloud.create_tag_image(taglist2, 'wordcloud_u.jpg', fontname='Korean', size=(500, 320), layout=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frozen = np.array(df_frozen['text'])\n",
    "frozen_str = ' '.join(frozen).decode('utf-8')\n",
    "unfrozen = np.array(df_unfrozen['text2'])\n",
    "unfrozen_str = ' '.join(unfrozen).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = tokenize_basic(frozen_str)\n",
    "counter = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "for k, v in counter.most_common(100):\n",
    "    stop_words.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('stopwords.txt', 'w') as words :\n",
    "    words.write(','.join(stop_words).encode('utf-8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
